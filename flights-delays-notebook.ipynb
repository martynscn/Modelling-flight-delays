{"cells": [{"metadata": {"id": "40a353bdf82d4b5e85530a88db5fbe6c"}, "cell_type": "markdown", "source": "# Flight delays\n\n### Packages update\n\nWe first need to update Seaborn to its latest version (0.11.1) to use some of its latest features."}, {"metadata": {"id": "faf086f0969345778374f644f3c828c8"}, "cell_type": "code", "source": "!conda install seaborn==0.11.1\n\nimport pandas as pd\nimport seaborn as sns", "execution_count": null, "outputs": []}, {"metadata": {"id": "40a353bdf82d4b5e85530a88db5fbe6c"}, "cell_type": "markdown", "source": "### Dataset loading\n\nWe load the dataset using [pandas](https://pandas.pydata.org/), and display basic information: its shape, columns and a sample of the first rows.\n<p style=\"color:red;font-size: medium\">\n    <b>Insert code in the cell below:</b><br><br>\n    1. Click on the cell below to position your cursor in it.<br>\n    2. Click on the top-right icon that says '<i>Find and add data</i>' when you hover your mouse over it.<br>\n    3. Choose the '<i>Flights-Jan2019_csv_shaped</i>' dataset and pick '<i>pandas DataFrame</i>' in the drop-down list.<br>\n</p>"}, {"metadata": {"id": "07abda45-ef95-4b3a-94d2-e26bdc2f5d55"}, "cell_type": "code", "source": "# INSERT CODE HERE", "execution_count": null, "outputs": []}, {"metadata": {"id": "07abda45-ef95-4b3a-94d2-e26bdc2f5d55"}, "cell_type": "code", "source": "df = df_data_1 # rename to a shorter name\nprint(df.shape, df.dtypes, df.head(), sep=\"\\n\\n\\n\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "677cfd67cc0f4ee5a1ec56f131e81303"}, "cell_type": "markdown", "source": "That dataset contains __583 985 rows__ and __14 columns__ with information on departure and arrival airports, flights time, ..."}, {"metadata": {"id": "be567a2e1c3a46d6aeba9b0e89a5128d"}, "cell_type": "markdown", "source": "### Preprocessing\n\nMore complex preprocessing can be directly performed in a notebook instead of using the Data Refinery service. At the end of the notebook, we will save the resulting dataset as a new CP4D project asset.\n\n#### Create target column\n\nWe create a `FLIGHT_STATUS` column which merges the `CANCELLED` and `DIVERTED` columns, and set flights with no issue to `ONTIME`. This will be the target column to predict."}, {"metadata": {"id": "d8c49534532e412881ad6e011c83024b"}, "cell_type": "code", "source": "df.CANCELLED = df.CANCELLED.transform(lambda x: \"CANCELLED\" if x == 1.0 else \"\")\ndf.DIVERTED = df.DIVERTED.transform(lambda x: \"DIVERTED\" if x == 1.0 else \"\")\ndf[\"FLIGHT_STATUS\"] = (df.CANCELLED + df.DIVERTED).replace(\"\", \"ONTIME\")\ndf.drop([\"CANCELLED\", \"DIVERTED\"], axis=1, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {"id": "4bc9ad8bb9d54afb9122522d4abab87c"}, "cell_type": "code", "source": "df.FLIGHT_STATUS.value_counts(normalize=True)", "execution_count": null, "outputs": []}, {"metadata": {"id": "c4db42fdecfc426dac1e043d8d0e9e93"}, "cell_type": "markdown", "source": "The dataset is logically highly unbalanced with __96.9% flights on time__.\n\n### Visualization\n\nWe now visualize several aspects of the dataset to better understand the data and refine the preprocessing if needed.\n\n#### Top 10 airports"}, {"metadata": {"id": "dff95825e077445e967624049d88c279"}, "cell_type": "code", "source": "df_Origin = pd.DataFrame(df[\"ORIGIN\"].value_counts().nlargest(n=10))\nsns.barplot(x=df_Origin.index, y=\"ORIGIN\", data=df_Origin)", "execution_count": null, "outputs": []}, {"metadata": {"id": "757f13b1a42548049c8a40a3ab51f05e"}, "cell_type": "markdown", "source": "This shows the 10 airports with most flights; the most frequented one (with more than 30 000 departure flights in January 2019) is `ATL` (for Hartsfield-Jackson International Airport in Atlanta).\n\n#### Flights per hour\n\nThe following plot displays the number of flights according to hours of the day (as specified in the `DEP_TIME_BLK` variable)."}, {"metadata": {"id": "c22990d379a847c188514fb728d7746e"}, "cell_type": "code", "source": "df_DepTime = pd.DataFrame(df[\"DEP_TIME_BLK\"].value_counts())\nsns.barplot(x=df_DepTime.DEP_TIME_BLK, y=df_DepTime.index, order=sorted(df_DepTime.index), palette=\"crest\", orient=\"h\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "a2835f4463a447b78de383bf957b1ec7"}, "cell_type": "markdown", "source": "#### Distribution histograms\n\nThis plot shows the distribution of variables in the dataset."}, {"metadata": {"id": "8b3b767da7f74cc18d2115bbbb344e07"}, "cell_type": "code", "source": "df.hist(figsize=(20,10))", "execution_count": null, "outputs": []}, {"metadata": {"id": "85e98f758daf4124969ba467d721b14b"}, "cell_type": "markdown", "source": "#### Correlation matrix\n\nThis final plot displays how variables are pair-wise dependent."}, {"metadata": {"id": "e312b838a2d248a3881a8927414e0ed4"}, "cell_type": "code", "source": "sns.heatmap(df.corr())", "execution_count": null, "outputs": []}, {"metadata": {"id": "183839f4291f43ecac0862c1c94eade4"}, "cell_type": "markdown", "source": "### Preprocessing again\n\nWe can check the NaN values in the dataset, and notice that some column values are always NaN for cancelled flights: departure and arrival times, for obvious reasons. <br>\nThis means we can't use these columns because they are biased (we don't know the theoretical departure time of cancelled flights) and need to be excluded."}, {"metadata": {"id": "590dc84e2edf47a288e23cfc4d96b570"}, "cell_type": "code", "source": "df[df.FLIGHT_STATUS == \"CANCELLED\"].isna().mean()", "execution_count": null, "outputs": []}, {"metadata": {"id": "183839f4291f43ecac0862c1c94eade4"}, "cell_type": "markdown", "source": "We therefore drop these columns, and save that new dataset as a CP4D asset. <br>\nNote that this could have been done through Data Refinery again, this is to show that both options are possible to preprocess a dataset."}, {"metadata": {"id": "f2e760a21b954fa287f21a354552f8a2"}, "cell_type": "code", "source": "df.drop([\"DEP_TIME\", \"DEP_DEL15\", \"ARR_TIME\", \"ARR_DEL15\"], axis=1, inplace=True)\n\nfrom project_lib import Project\nProject.access().save_data(\"Flights-Jan2019-Clean.csv\", df.to_csv(index=False))", "execution_count": null, "outputs": []}, {"metadata": {"id": "cf496cb9e053457485875de13ad8abc1"}, "cell_type": "markdown", "source": "__END__"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}